{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05dd1df4-d301-486e-ba1c-4af492dc52d1",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f42b923a-394c-4577-afda-987a63800d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'hfl/rbt3'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7919da3-9ab1-4ab8-a0b2-861303fc2ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='hfl/rbt3', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2bdb20c5-628b-400c-b8ea-b107eedb9037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 3217, 1921, 3221, 1391, 1102, 3899, 1119, 4638, 3198, 5688, 102], [101, 2769, 1762, 1599, 7716, 2861, 7414, 2255, 4638, 677, 4958, 2835, 5291, 7607, 3322, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trail\n",
    "tokenizer.batch_encode_plus(['Êò•Â§©ÊòØÂêÉÂÜ∞Ê∑áÂáåÁöÑÊó∂ËäÇ', 'ÊàëÂú®ÂñúÈ©¨ÊãâÈõÖÂ±±ÁöÑ‰∏äÁ©∫ÊäòÁ∫∏È£ûÊú∫'], truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8fbde20b-c842-499e-aa0b-93441b46a113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "dataset = load_from_disk('../ChnSentiCorp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c508943-0352-47d5-a0ed-13cc5757fa55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 9600\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 0\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b70dea6-a75a-4ee6-9168-86280ad58007",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'] = dataset['train'].shuffle().select(range(2000))\n",
    "dataset['test'] = dataset['test'].shuffle().select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f77f599d-d78b-4206-95de-5c0e614a4e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '‰ΩúËÄÖÊúâ‰∏ÄÁßç‰∏ì‰∏öÁöÑË∞®ÊÖéÔºåËã•ËÉΩÊúâÂπ∏Â≠¶‰π†ÂéüÁâà‰πüËÆ∏‰ºöÊõ¥Â•ΩÔºåÁÆÄ‰ΩìÁâàÁöÑ‰π¶‰∏≠ÁöÑÂç∞Âà∑ÈîôËØØÊØîËæÉÂ§öÔºåÂΩ±ÂìçÂ≠¶ËÄÖÁêÜËß£ÔºåÂÖ®‰π¶ÁªìÊûÑÁÆÄÂçïÔºå‰ΩÜÂÜÖÂÆπËØ¶ÂÆûÔºåÂ≠¶Ëµ∑Êù•Â¶ÇÈ±ºÂæóÊ∞¥ÈùûÂ∏∏ËΩªÊùæ„ÄÇËøôÂè™ÊòØ‰∏ÄÈ°πÊäÄÊúØËÄåÂ∑≤ÔºåËã•ÂèØ‰ª•ÁªìÂêàÊú¨‰∏ì‰∏öÔºåÂ∞Ü‰ºöÂæóÂà∞Êõ¥È´òÁöÑÂ≠¶‰π†Âø´‰πêÔºåÂÆ∂Ë¥¢‰∏áË¥Ø‰∏çÂ¶Ç‰∏ÄÊäÄÂú®Ë∫´Ôºå‰∏ÄÊäÄÂú®Ë∫´‰∏çÂ¶Ç‰∏ÄÂøµÂú®ÂøÉÔºåÊú¨‰π¶Êúâ‰∏ç‰ªÖÊúâÊäÄÔºåËÄå‰∏îÊúâÂøµ„ÄÇ‰π¶‰∏≠‰Ω≥ÂìÅ„ÄÇ',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de59c1dd-b3a5-4dc6-aab8-ce020885069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(data, tokenizer):\n",
    "    return tokenizer.batch_encode_plus(data['text'], truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d892353-859a-41e2-a4ba-de41b6d3a7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690802e05be74ba59ab51af0d9cbdb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948b339d00e94e2fadb6d435319c1f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(f,\n",
    "                      batched = True,\n",
    "                      batch_size = 1000,\n",
    "                      num_proc = 4,\n",
    "                      remove_columns = ['text'],\n",
    "                      fn_kwargs = {'tokenizer':tokenizer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bfa4e2f4-0225-40d1-a8ef-a42b8ecd3c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label'],\n",
       "        num_rows: 0\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bfc9e6b9-dd33-4b0d-85be-6f042a96072d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'input_ids': [101,\n",
       "  868,\n",
       "  5442,\n",
       "  3300,\n",
       "  671,\n",
       "  4905,\n",
       "  683,\n",
       "  689,\n",
       "  4638,\n",
       "  6474,\n",
       "  2708,\n",
       "  8024,\n",
       "  5735,\n",
       "  5543,\n",
       "  3300,\n",
       "  2401,\n",
       "  2110,\n",
       "  739,\n",
       "  1333,\n",
       "  4276,\n",
       "  738,\n",
       "  6387,\n",
       "  833,\n",
       "  3291,\n",
       "  1962,\n",
       "  8024,\n",
       "  5042,\n",
       "  860,\n",
       "  4276,\n",
       "  4638,\n",
       "  741,\n",
       "  704,\n",
       "  4638,\n",
       "  1313,\n",
       "  1170,\n",
       "  7231,\n",
       "  6428,\n",
       "  3683,\n",
       "  6772,\n",
       "  1914,\n",
       "  8024,\n",
       "  2512,\n",
       "  1510,\n",
       "  2110,\n",
       "  5442,\n",
       "  4415,\n",
       "  6237,\n",
       "  8024,\n",
       "  1059,\n",
       "  741,\n",
       "  5310,\n",
       "  3354,\n",
       "  5042,\n",
       "  1296,\n",
       "  8024,\n",
       "  852,\n",
       "  1079,\n",
       "  2159,\n",
       "  6422,\n",
       "  2141,\n",
       "  8024,\n",
       "  2110,\n",
       "  6629,\n",
       "  3341,\n",
       "  1963,\n",
       "  7824,\n",
       "  2533,\n",
       "  3717,\n",
       "  7478,\n",
       "  2382,\n",
       "  6768,\n",
       "  3351,\n",
       "  511,\n",
       "  6821,\n",
       "  1372,\n",
       "  3221,\n",
       "  671,\n",
       "  7555,\n",
       "  2825,\n",
       "  3318,\n",
       "  5445,\n",
       "  2347,\n",
       "  8024,\n",
       "  5735,\n",
       "  1377,\n",
       "  809,\n",
       "  5310,\n",
       "  1394,\n",
       "  3315,\n",
       "  683,\n",
       "  689,\n",
       "  8024,\n",
       "  2199,\n",
       "  833,\n",
       "  2533,\n",
       "  1168,\n",
       "  3291,\n",
       "  7770,\n",
       "  4638,\n",
       "  2110,\n",
       "  739,\n",
       "  2571,\n",
       "  727,\n",
       "  8024,\n",
       "  2157,\n",
       "  6568,\n",
       "  674,\n",
       "  6581,\n",
       "  679,\n",
       "  1963,\n",
       "  671,\n",
       "  2825,\n",
       "  1762,\n",
       "  6716,\n",
       "  8024,\n",
       "  671,\n",
       "  2825,\n",
       "  1762,\n",
       "  6716,\n",
       "  679,\n",
       "  1963,\n",
       "  671,\n",
       "  2573,\n",
       "  1762,\n",
       "  2552,\n",
       "  8024,\n",
       "  3315,\n",
       "  741,\n",
       "  3300,\n",
       "  679,\n",
       "  788,\n",
       "  3300,\n",
       "  2825,\n",
       "  8024,\n",
       "  5445,\n",
       "  684,\n",
       "  3300,\n",
       "  2573,\n",
       "  511,\n",
       "  741,\n",
       "  704,\n",
       "  881,\n",
       "  1501,\n",
       "  511,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0cd4546-5eb2-4544-bca8-9955678366d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8846d114d6b41028b7f7e7bf7125dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45287e9a755a4189a1589adc3f23b557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# delete long sentences\n",
    "def f2(data):\n",
    "    return [len(i) <=  512 for i in data['input_ids']]\n",
    "\n",
    "dataset = dataset.filter(\n",
    "    f2,\n",
    "    batched = True,\n",
    "    batch_size = 1000,\n",
    "    num_proc = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c770f-d783-40a8-9fb8-a8c72a9b46b7",
   "metadata": {},
   "source": [
    "`batch_size` doesn‚Äôt change what gets filtered (the output result will be the same) ‚Äîit just controls how efficiently the filtering happens.\n",
    "- It affects memory usage: Larger batches use more RAM.\n",
    "- It affects speed: Larger batches usually mean fewer function calls and faster processing.\n",
    "- It affects parallelism: With num_proc=4, each of the 4 processes will handle batches of 1000 examples independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6c2b7648-09c0-403e-9f9c-f84d760ff0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7bce0987-13f6-48b7-9051-7c9f42bed3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.41.0\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "235c8426-9011-4011-bd13-1951237652a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: accelerate\n",
      "Version: 0.30.0\n",
      "Summary: Accelerate\n",
      "Home-page: https://github.com/huggingface/accelerate\n",
      "Author: The HuggingFace team\n",
      "Author-email: zach.mueller@huggingface.co\n",
      "License: Apache\n",
      "Location: /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages\n",
      "Requires: huggingface-hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cad8a7e9-5303-4f51-9d73-60d091a73daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4fed67bf2a4a7d99ae55700983086b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/156M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/rbt3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model = AutoModelForSequenceClassification.from_pretrained('hfl/rbt3', num_labels=2)\n",
    "model = BertForSequenceClassification.from_pretrained('hfl/rbt3', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c4f91406-55b0-4db4-9adc-de754a166521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38478338"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i.nelement() for i in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae1b6b6-988c-465c-82e5-0a2221d5acfe",
   "metadata": {},
   "source": [
    "There are about 38 millions parameters in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "87523c53-4200-43d9-814c-7db2e6ae4006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ceb28e59-45b6-4b41-b08a-489cf9b1fa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trail\n",
    "data = {\n",
    "    'input_ids': torch.ones(4,10, dtype = torch.long),\n",
    "    'token_type_ids': torch.ones(4,10, dtype = torch.long),\n",
    "    'attention_mask':torch.ones(4,10, dtype = torch.long),\n",
    "    'labels':torch.ones(4, dtype = torch.long),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "076cee09-d510-4608-a932-1fd9bb44e3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'token_type_ids': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'labels': tensor([1, 1, 1, 1])}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "638ab214-eb9d-4dd4-b58d-24ac44e474dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "09dfb829-af87-4c5e-b09c-fc67203836fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.7646, grad_fn=<NllLossBackward0>), logits=tensor([[ 0.0253, -0.1128],\n",
       "        [ 0.0253, -0.1128],\n",
       "        [ 0.0253, -0.1128],\n",
       "        [ 0.0253, -0.1128]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5557ea15-6044-47dd-9bc5-8ea16aa677a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7646, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a5f09438-b4a8-49c8-9f9a-be047438485c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0253, -0.1128],\n",
       "        [ 0.0253, -0.1128],\n",
       "        [ 0.0253, -0.1128],\n",
       "        [ 0.0253, -0.1128]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['logits']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1867139-7e11-4a2b-b529-93bed3149ee9",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "82e77331-e3c7-4884-90a5-8ae83db16598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load as load_metric\n",
    "metric = load_metric('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "310c9261-5063-40f8-8058-0ac0868abc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers.trainer_utils import EvalPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0b122c67-013c-4283-8477-4e9d160312ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    pred = logits.argmax(axis = 1)\n",
    "    print (pred)\n",
    "    return metric.compute(predictions = pred, references = labels)\n",
    "    # return {'accuracy' : (pred == labels).mean()}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ce3a392b-6c05-498e-a89c-c5ccddf79c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_pred = EvalPrediction(\n",
    "    predictions = np.array([[1,0],[9,3],[0.4,0.3],[6,7]]),\n",
    "    label_ids = np.array([1,1,0,1])\n",
    ")\n",
    "compute_metrics(eval_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e2b7f390-7c05-4fa3-a8e7-1299619afd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.trainer_utils.EvalPrediction at 0x3031157b0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688f7987-68c1-4e83-8603-a8d1206a4012",
   "metadata": {},
   "source": [
    "## Parameter in training\n",
    "In Huggingface, the parameters are packed in a **class -- TrainingArguments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cac01660-1f4f-4705-9964-2e64b5a0178f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.41.0 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (4.41.0)\n",
      "Requirement already satisfied: accelerate==0.30.0 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (0.30.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from transformers==4.41.0) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from transformers==4.41.0) (0.33.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from transformers==4.41.0) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from transformers==4.41.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from transformers==4.41.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from transformers==4.41.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from transformers==4.41.0) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from transformers==4.41.0) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from transformers==4.41.0) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from transformers==4.41.0) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from accelerate==0.30.0) (7.0.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from accelerate==0.30.0) (2.7.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.0) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.0) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.0) (1.1.5)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30.0) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.10.0->accelerate==0.30.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.30.0) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from requests->transformers==4.41.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from requests->transformers==4.41.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from requests->transformers==4.41.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages (from requests->transformers==4.41.0) (2025.6.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-cache-dir \"transformers==4.41.0\" \"accelerate==0.30.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b78b28-ca82-4c7c-8c79-028203aeedf1",
   "metadata": {},
   "source": [
    "I was using transformers 4.50.0 and accelerate 1.8.1, but they are not doing well with the below code.\n",
    "\n",
    "So I swithed to transfomers 4.41.0 and accelerate 0.30.0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "905cb2b9-ef0d-4e77-95c5-5b4c67b51cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "550acebc-40a7-46b2-a535-c818db5ae9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir = './output_dir', # temporary output data's saving path\n",
    "    # evaluation_strategy = 'steps',\n",
    "    \n",
    "    eval_steps = 30,#how many steps to perform an evaluation\n",
    "    save_strategy = 'steps', # it can be 'no', 'epoch', 'steps'\n",
    "    save_steps = 30,\n",
    "\n",
    "    num_train_epochs = 2,\n",
    "\n",
    "    learning_rate = 0.001,\n",
    "\n",
    "    weight_decay = 0.01, #ùúÜ to multiply on the sum of square of weights in loss function, to reduce overfitting\n",
    "\n",
    "    per_device_eval_batch_size = 16,\n",
    "    per_device_train_batch_size = 16,\n",
    "\n",
    "    no_cuda = False #It will us MPS if available\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a90a90db-420c-4ba2-9ac6-265f8028874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the trainer\n",
    "from transformers import Trainer\n",
    "from transformers.data.data_collator import DataCollatorWithPadding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "80fe5f85-a343-4d8f-b959-8fb9900ce039",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = args,\n",
    "    train_dataset = dataset['train'],\n",
    "    eval_dataset = dataset['test'],\n",
    "    compute_metrics = compute_metrics,\n",
    "    data_collator = DataCollatorWithPadding(tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e982513-bc61-4bb3-84d5-2367c4e1a81d",
   "metadata": {},
   "source": [
    "Data collator standadize the input data and make them the same length. Check out the test below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e49ad41a-0144-4aab-bc13-6557f973c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3d099aba-13a1-461f-ad35-782156020fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': [1, 1, 0, 0, 1], 'input_ids': [[101, 868, 5442, 3300, 671, 4905, 683, 689, 4638, 6474, 2708, 8024, 5735, 5543, 3300, 2401, 2110, 739, 1333, 4276, 738, 6387, 833, 3291, 1962, 8024, 5042, 860, 4276, 4638, 741, 704, 4638, 1313, 1170, 7231, 6428, 3683, 6772, 1914, 8024, 2512, 1510, 2110, 5442, 4415, 6237, 8024, 1059, 741, 5310, 3354, 5042, 1296, 8024, 852, 1079, 2159, 6422, 2141, 8024, 2110, 6629, 3341, 1963, 7824, 2533, 3717, 7478, 2382, 6768, 3351, 511, 6821, 1372, 3221, 671, 7555, 2825, 3318, 5445, 2347, 8024, 5735, 1377, 809, 5310, 1394, 3315, 683, 689, 8024, 2199, 833, 2533, 1168, 3291, 7770, 4638, 2110, 739, 2571, 727, 8024, 2157, 6568, 674, 6581, 679, 1963, 671, 2825, 1762, 6716, 8024, 671, 2825, 1762, 6716, 679, 1963, 671, 2573, 1762, 2552, 8024, 3315, 741, 3300, 679, 788, 3300, 2825, 8024, 5445, 684, 3300, 2573, 511, 741, 704, 881, 1501, 511, 102], [101, 3296, 3301, 1351, 6370, 4638, 2791, 7313, 8024, 2945, 6432, 6820, 679, 7231, 1568, 8024, 671, 678, 1726, 8024, 5632, 2346, 1343, 6407, 6407, 511, 102], [101, 7444, 6206, 5632, 2346, 2128, 6163, 5143, 5320, 8024, 1912, 6121, 4638, 1377, 5543, 833, 3300, 7309, 7579, 4638, 8024, 976, 1962, 2552, 4415, 1114, 1906, 1373, 782, 2376, 2564, 6163, 3322, 8013, 102], [101, 2791, 7313, 2523, 1920, 1456, 6887, 8024, 3302, 1218, 2345, 8024, 2578, 2428, 2345, 8024, 2791, 1296, 6392, 3177, 2345, 172, 172, 3719, 6823, 679, 833, 1086, 1343, 749, 511, 2345, 2218, 671, 702, 2099, 102], [101, 1146, 1277, 3198, 1139, 4385, 2867, 5318, 6393, 7309, 8024, 2582, 720, 1146, 6963, 679, 6121, 8024, 6435, 3724, 2376, 1221, 8013, 6843, 4638, 10719, 1079, 2100, 3340, 8024, 2582, 720, 2128, 6163, 1450, 8043, 2418, 6421, 679, 5543, 5632, 2346, 3078, 5632, 2128, 6163, 1416, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "data = dataset['train'][:5]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a5313e04-9d87-4224-a18e-481520a4a43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n",
      "27\n",
      "35\n",
      "37\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "for i in data['input_ids']:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c5a7a869-78d7-48ec-8a47-535ab43cbc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the data_collator\n",
    "data = data_collator(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "97333dae-2d57-45d9-bf3f-aeb1bd8fcc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,   868,  5442,  3300,   671,  4905,   683,   689,  4638,  6474,\n",
       "          2708,  8024,  5735,  5543,  3300,  2401,  2110,   739,  1333,  4276,\n",
       "           738,  6387,   833,  3291,  1962,  8024,  5042,   860,  4276,  4638,\n",
       "           741,   704,  4638,  1313,  1170,  7231,  6428,  3683,  6772,  1914,\n",
       "          8024,  2512,  1510,  2110,  5442,  4415,  6237,  8024,  1059,   741,\n",
       "          5310,  3354,  5042,  1296,  8024,   852,  1079,  2159,  6422,  2141,\n",
       "          8024,  2110,  6629,  3341,  1963,  7824,  2533,  3717,  7478,  2382,\n",
       "          6768,  3351,   511,  6821,  1372,  3221,   671,  7555,  2825,  3318,\n",
       "          5445,  2347,  8024,  5735,  1377,   809,  5310,  1394,  3315,   683,\n",
       "           689,  8024,  2199,   833,  2533,  1168,  3291,  7770,  4638,  2110,\n",
       "           739,  2571,   727,  8024,  2157,  6568,   674,  6581,   679,  1963,\n",
       "           671,  2825,  1762,  6716,  8024,   671,  2825,  1762,  6716,   679,\n",
       "          1963,   671,  2573,  1762,  2552,  8024,  3315,   741,  3300,   679,\n",
       "           788,  3300,  2825,  8024,  5445,   684,  3300,  2573,   511,   741,\n",
       "           704,   881,  1501,   511,   102],\n",
       "        [  101,  3296,  3301,  1351,  6370,  4638,  2791,  7313,  8024,  2945,\n",
       "          6432,  6820,   679,  7231,  1568,  8024,   671,   678,  1726,  8024,\n",
       "          5632,  2346,  1343,  6407,  6407,   511,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [  101,  7444,  6206,  5632,  2346,  2128,  6163,  5143,  5320,  8024,\n",
       "          1912,  6121,  4638,  1377,  5543,   833,  3300,  7309,  7579,  4638,\n",
       "          8024,   976,  1962,  2552,  4415,  1114,  1906,  1373,   782,  2376,\n",
       "          2564,  6163,  3322,  8013,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [  101,  2791,  7313,  2523,  1920,  1456,  6887,  8024,  3302,  1218,\n",
       "          2345,  8024,  2578,  2428,  2345,  8024,  2791,  1296,  6392,  3177,\n",
       "          2345,   172,   172,  3719,  6823,   679,   833,  1086,  1343,   749,\n",
       "           511,  2345,  2218,   671,   702,  2099,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [  101,  1146,  1277,  3198,  1139,  4385,  2867,  5318,  6393,  7309,\n",
       "          8024,  2582,   720,  1146,  6963,   679,  6121,  8024,  6435,  3724,\n",
       "          2376,  1221,  8013,  6843,  4638, 10719,  1079,  2100,  3340,  8024,\n",
       "          2582,   720,  2128,  6163,  1450,  8043,  2418,  6421,   679,  5543,\n",
       "          5632,  2346,  3078,  5632,  2128,  6163,  1416,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0]]), 'labels': tensor([1, 1, 0, 0, 1])}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7c39c0a2-5f2f-4bb3-aeba-3dbcf5df759a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([5, 145])\n",
      "token_type_ids torch.Size([5, 145])\n",
      "attention_mask torch.Size([5, 145])\n",
      "labels torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "for k, v in data.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b73c6b7a-55df-45be-b0fb-dcef94476490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Êõø Êúã Âèã ËÆ¢ ÁöÑ Êàø Èó¥ Ôºå ÊçÆ ËØ¥ Ëøò ‰∏ç Èîô Âï¶ Ôºå ‰∏Ä ‰∏ã Âõû Ôºå Ëá™ Â∑± Âéª ËØï ËØï „ÄÇ [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(data['input_ids'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c1b649-d2f6-4ffc-94cd-39b50b62a971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
