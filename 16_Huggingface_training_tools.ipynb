{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05dd1df4-d301-486e-ba1c-4af492dc52d1",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f42b923a-394c-4577-afda-987a63800d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'hfl/rbt3'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7919da3-9ab1-4ab8-a0b2-861303fc2ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='hfl/rbt3', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bdb20c5-628b-400c-b8ea-b107eedb9037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 3217, 1921, 3221, 1391, 1102, 3899, 1119, 4638, 3198, 5688, 102], [101, 2769, 1762, 1599, 7716, 2861, 7414, 2255, 4638, 677, 4958, 2835, 5291, 7607, 3322, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trail\n",
    "tokenizer.batch_encode_plus(['Êò•Â§©ÊòØÂêÉÂÜ∞Ê∑áÂáåÁöÑÊó∂ËäÇ', 'ÊàëÂú®ÂñúÈ©¨ÊãâÈõÖÂ±±ÁöÑ‰∏äÁ©∫ÊäòÁ∫∏È£ûÊú∫'], truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fbde20b-c842-499e-aa0b-93441b46a113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "dataset = load_from_disk('../ChnSentiCorp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c508943-0352-47d5-a0ed-13cc5757fa55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 9600\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 0\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b70dea6-a75a-4ee6-9168-86280ad58007",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'] = dataset['train'].shuffle().select(range(2000))\n",
    "dataset['test'] = dataset['test'].shuffle().select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f77f599d-d78b-4206-95de-5c0e614a4e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '‰ª∑Ê†ºËøòÂèØ‰ª•ÂÜçÂæÄ‰∏ã‰∏ÄÁÇπ(Ê∏ØË°åËøô‰∏™‰ª∑Èí±ÂèØÊòØÂèåÁîµ+ÂÜÖÂåÖ+xp),3ËäØÁîµÊ±†ÊúâÁÇπÂ∞è,1gÂÜÖÂ≠òÊúâÁÇπÂ∞è,ÊúÄÈáçË¶ÅÁöÑÊòØÂàÜËæ®ÁéáÊòØ1024*576,Ëøô‰∏™ÊúâÁÇπÁÉ¶',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de59c1dd-b3a5-4dc6-aab8-ce020885069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(data, tokenizer):\n",
    "    return tokenizer.batch_encode_plus(data['text'], truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d892353-859a-41e2-a4ba-de41b6d3a7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d7c1360890c4a4ab985d4d0444abe10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2873d715276c4e15864aceb6e5269630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(f,\n",
    "                      batched = True,\n",
    "                      batch_size = 1000,\n",
    "                      num_proc = 4,\n",
    "                      remove_columns = ['text'],\n",
    "                      fn_kwargs = {'tokenizer':tokenizer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfa4e2f4-0225-40d1-a8ef-a42b8ecd3c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label'],\n",
       "        num_rows: 0\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfc9e6b9-dd33-4b0d-85be-6f042a96072d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'input_ids': [101,\n",
       "  817,\n",
       "  3419,\n",
       "  6820,\n",
       "  1377,\n",
       "  809,\n",
       "  1086,\n",
       "  2518,\n",
       "  678,\n",
       "  671,\n",
       "  4157,\n",
       "  113,\n",
       "  3949,\n",
       "  6121,\n",
       "  6821,\n",
       "  702,\n",
       "  817,\n",
       "  7178,\n",
       "  1377,\n",
       "  3221,\n",
       "  1352,\n",
       "  4510,\n",
       "  116,\n",
       "  1079,\n",
       "  1259,\n",
       "  116,\n",
       "  8766,\n",
       "  114,\n",
       "  117,\n",
       "  124,\n",
       "  5708,\n",
       "  4510,\n",
       "  3737,\n",
       "  3300,\n",
       "  4157,\n",
       "  2207,\n",
       "  117,\n",
       "  10719,\n",
       "  1079,\n",
       "  2100,\n",
       "  3300,\n",
       "  4157,\n",
       "  2207,\n",
       "  117,\n",
       "  3297,\n",
       "  7028,\n",
       "  6206,\n",
       "  4638,\n",
       "  3221,\n",
       "  1146,\n",
       "  6795,\n",
       "  4372,\n",
       "  3221,\n",
       "  11570,\n",
       "  115,\n",
       "  8272,\n",
       "  8158,\n",
       "  117,\n",
       "  6821,\n",
       "  702,\n",
       "  3300,\n",
       "  4157,\n",
       "  4172,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0cd4546-5eb2-4544-bca8-9955678366d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5854e05cf9b4cb3b26f95c91df5f61c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68f8a38eef84b529108c969a1f1727d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# delete long sentences\n",
    "def f2(data):\n",
    "    return [len(i) <=  512 for i in data['input_ids']]\n",
    "\n",
    "dataset = dataset.filter(\n",
    "    f2,\n",
    "    batched = True,\n",
    "    batch_size = 1000,\n",
    "    num_proc = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c770f-d783-40a8-9fb8-a8c72a9b46b7",
   "metadata": {},
   "source": [
    "`batch_size` doesn‚Äôt change what gets filtered (the output result will be the same) ‚Äîit just controls how efficiently the filtering happens.\n",
    "- It affects memory usage: Larger batches use more RAM.\n",
    "- It affects speed: Larger batches usually mean fewer function calls and faster processing.\n",
    "- It affects parallelism: With num_proc=4, each of the 4 processes will handle batches of 1000 examples independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c2b7648-09c0-403e-9f9c-f84d760ff0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0705 11:40:19.551000 34752 site-packages/torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bce0987-13f6-48b7-9051-7c9f42bed3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.41.0\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "235c8426-9011-4011-bd13-1951237652a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: accelerate\n",
      "Version: 0.30.0\n",
      "Summary: Accelerate\n",
      "Home-page: https://github.com/huggingface/accelerate\n",
      "Author: The HuggingFace team\n",
      "Author-email: zach.mueller@huggingface.co\n",
      "License: Apache\n",
      "Location: /opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages\n",
      "Requires: huggingface-hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cad8a7e9-5303-4f51-9d73-60d091a73daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/rbt3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model = AutoModelForSequenceClassification.from_pretrained('hfl/rbt3', num_labels=2)\n",
    "model = BertForSequenceClassification.from_pretrained('hfl/rbt3', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4f91406-55b0-4db4-9adc-de754a166521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38478338"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i.nelement() for i in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae1b6b6-988c-465c-82e5-0a2221d5acfe",
   "metadata": {},
   "source": [
    "There are about 38 millions parameters in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87523c53-4200-43d9-814c-7db2e6ae4006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ceb28e59-45b6-4b41-b08a-489cf9b1fa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trail\n",
    "data = {\n",
    "    'input_ids': torch.ones(4,10, dtype = torch.long),\n",
    "    'token_type_ids': torch.ones(4,10, dtype = torch.long),\n",
    "    'attention_mask':torch.ones(4,10, dtype = torch.long),\n",
    "    'labels':torch.ones(4, dtype = torch.long),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "076cee09-d510-4608-a932-1fd9bb44e3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'token_type_ids': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'labels': tensor([1, 1, 1, 1])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "638ab214-eb9d-4dd4-b58d-24ac44e474dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09dfb829-af87-4c5e-b09c-fc67203836fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.9882, grad_fn=<NllLossBackward0>), logits=tensor([[ 0.0209, -0.5017],\n",
       "        [ 0.0209, -0.5017],\n",
       "        [ 0.0209, -0.5017],\n",
       "        [ 0.0209, -0.5017]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5557ea15-6044-47dd-9bc5-8ea16aa677a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9882, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5f09438-b4a8-49c8-9f9a-be047438485c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0209, -0.5017],\n",
       "        [ 0.0209, -0.5017],\n",
       "        [ 0.0209, -0.5017],\n",
       "        [ 0.0209, -0.5017]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['logits']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1867139-7e11-4a2b-b529-93bed3149ee9",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82e77331-e3c7-4884-90a5-8ae83db16598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load as load_metric\n",
    "metric = load_metric('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "310c9261-5063-40f8-8058-0ac0868abc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers.trainer_utils import EvalPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b122c67-013c-4283-8477-4e9d160312ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    pred = logits.argmax(axis = 1)\n",
    "    print (pred)\n",
    "    return metric.compute(predictions = pred, references = labels)\n",
    "    # return {'accuracy' : (pred == labels).mean()}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce3a392b-6c05-498e-a89c-c5ccddf79c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pred = EvalPrediction(\n",
    "    predictions = np.array([[1,0],[9,3],[0.4,0.3],[6,7]]),\n",
    "    label_ids = np.array([1,1,0,1])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2b7f390-7c05-4fa3-a8e7-1299619afd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, labels = eval_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd74b9aa-6926-4674-a3e0-3fbad03d90f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0. ],\n",
       "       [9. , 3. ],\n",
       "       [0.4, 0.3],\n",
       "       [6. , 7. ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3cd60490-957f-4d9f-b32f-8c629e9aa836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38d009d8-6587-4564-9f5b-75af62606f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8e45a46-8c2e-4209-b209-7b212a1ecba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(eval_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688f7987-68c1-4e83-8603-a8d1206a4012",
   "metadata": {},
   "source": [
    "## Parameter in training\n",
    "In Huggingface, the training parameters are packed in a **class -- TrainingArguments**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b78b28-ca82-4c7c-8c79-028203aeedf1",
   "metadata": {},
   "source": [
    "I was using transformers 4.50.0 and accelerate 1.8.1, but they are not doing well with the below code.\n",
    "\n",
    "So I swithed to transfomers 4.41.0 and accelerate 0.30.0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "905cb2b9-ef0d-4e77-95c5-5b4c67b51cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "550acebc-40a7-46b2-a535-c818db5ae9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir = './output_dir', # temporary output data's saving path\n",
    "    # evaluation_strategy = 'steps',\n",
    "    \n",
    "    eval_steps = 30,#how many steps to perform an evaluation\n",
    "    save_strategy = 'steps', # it can be 'no', 'epoch', 'steps'\n",
    "    save_steps = 30,\n",
    "\n",
    "    num_train_epochs = 2,\n",
    "\n",
    "    learning_rate = 0.001,\n",
    "\n",
    "    weight_decay = 0.01, #ùúÜ to multiply on the sum of square of weights in loss function, to reduce overfitting\n",
    "\n",
    "    per_device_eval_batch_size = 8,\n",
    "    per_device_train_batch_size = 8,\n",
    "\n",
    "    no_cuda = False, #It will use MPS if available\n",
    "\n",
    "    optim=\"adamw_torch\",\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a90a90db-420c-4ba2-9ac6-265f8028874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the trainer\n",
    "from transformers import Trainer\n",
    "from transformers.data.data_collator import DataCollatorWithPadding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80fe5f85-a343-4d8f-b959-8fb9900ce039",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = args,\n",
    "    train_dataset = dataset['train'],\n",
    "    eval_dataset = dataset['test'],\n",
    "    compute_metrics = compute_metrics,\n",
    "    data_collator = DataCollatorWithPadding(tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e982513-bc61-4bb3-84d5-2367c4e1a81d",
   "metadata": {},
   "source": [
    "Data collator standadize the input data and make them the same length. Check out the test below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e49ad41a-0144-4aab-bc13-6557f973c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d099aba-13a1-461f-ad35-782156020fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': [0, 0, 0, 0, 0], 'input_ids': [[101, 122, 8021, 2242, 2391, 3221, 100, 7262, 7481, 100, 4638, 8024, 680, 2145, 3302, 722, 1184, 4638, 1726, 5031, 4685, 1353, 1557, 8020, 2769, 702, 782, 1599, 3614, 4836, 3763, 7481, 4638, 8024, 7262, 7481, 1922, 3230, 4706, 8021, 8013, 123, 8021, 7599, 2794, 1898, 7509, 3683, 2682, 6496, 4638, 1920, 679, 2208, 8013, 124, 8021, 8403, 2940, 9769, 11379, 8024, 5905, 2242, 8024, 7444, 6206, 934, 3121, 9324, 6392, 5390, 8020, 4801, 4669, 1346, 3144, 3121, 711, 11319, 3175, 2466, 8021, 102], [101, 7564, 6163, 8403, 3221, 711, 749, 5688, 4689, 2768, 3315, 1416, 8024, 2940, 5143, 5320, 4924, 7937, 4172, 749, 4157, 511, 7241, 4669, 4802, 2141, 3300, 4157, 1510, 2418, 679, 6639, 4638, 7309, 7579, 8024, 2902, 7241, 6206, 4924, 4500, 1213, 8020, 679, 6814, 1377, 5543, 3221, 1728, 711, 3173, 3315, 2094, 679, 5650, 2533, 4500, 1213, 2902, 4638, 1333, 1728, 8021, 511, 1377, 5543, 3221, 3227, 1305, 1922, 4162, 1416, 8024, 2802, 3952, 2767, 3126, 3362, 679, 4415, 2682, 511, 102], [101, 7946, 2421, 1557, 8013, 8013, 8013, 8110, 4157, 1288, 6842, 2791, 2218, 6206, 1217, 3119, 1288, 1921, 2791, 6589, 6820, 2523, 3566, 2791, 7313, 2523, 3266, 8013, 8013, 8013, 8013, 3683, 6772, 3191, 8013, 8013, 102], [101, 2140, 2140, 671, 2259, 673, 702, 3299, 117, 679, 3221, 1922, 1599, 3614, 117, 738, 6387, 3221, 1728, 711, 5682, 2506, 679, 1916, 7831, 5683, 119, 5445, 684, 2190, 800, 5445, 6241, 117, 1377, 5543, 1922, 5042, 1296, 749, 119, 102], [101, 7478, 2382, 671, 5663, 4638, 671, 3315, 741, 8024, 1041, 4007, 749, 969, 2682, 4638, 4415, 2682, 712, 721, 5682, 2506, 8024, 2456, 6379, 1157, 3684, 689, 4638, 5466, 1767, 3173, 782, 1283, 674, 679, 6206, 4692, 511, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "data = dataset['train'][:5]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "316b8389-df13-4745-bdb2-f1d2dfd8fd7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': [0, 0, 0, 0, 0],\n",
       " 'input_ids': [[101,\n",
       "   122,\n",
       "   8021,\n",
       "   2242,\n",
       "   2391,\n",
       "   3221,\n",
       "   100,\n",
       "   7262,\n",
       "   7481,\n",
       "   100,\n",
       "   4638,\n",
       "   8024,\n",
       "   680,\n",
       "   2145,\n",
       "   3302,\n",
       "   722,\n",
       "   1184,\n",
       "   4638,\n",
       "   1726,\n",
       "   5031,\n",
       "   4685,\n",
       "   1353,\n",
       "   1557,\n",
       "   8020,\n",
       "   2769,\n",
       "   702,\n",
       "   782,\n",
       "   1599,\n",
       "   3614,\n",
       "   4836,\n",
       "   3763,\n",
       "   7481,\n",
       "   4638,\n",
       "   8024,\n",
       "   7262,\n",
       "   7481,\n",
       "   1922,\n",
       "   3230,\n",
       "   4706,\n",
       "   8021,\n",
       "   8013,\n",
       "   123,\n",
       "   8021,\n",
       "   7599,\n",
       "   2794,\n",
       "   1898,\n",
       "   7509,\n",
       "   3683,\n",
       "   2682,\n",
       "   6496,\n",
       "   4638,\n",
       "   1920,\n",
       "   679,\n",
       "   2208,\n",
       "   8013,\n",
       "   124,\n",
       "   8021,\n",
       "   8403,\n",
       "   2940,\n",
       "   9769,\n",
       "   11379,\n",
       "   8024,\n",
       "   5905,\n",
       "   2242,\n",
       "   8024,\n",
       "   7444,\n",
       "   6206,\n",
       "   934,\n",
       "   3121,\n",
       "   9324,\n",
       "   6392,\n",
       "   5390,\n",
       "   8020,\n",
       "   4801,\n",
       "   4669,\n",
       "   1346,\n",
       "   3144,\n",
       "   3121,\n",
       "   711,\n",
       "   11319,\n",
       "   3175,\n",
       "   2466,\n",
       "   8021,\n",
       "   102],\n",
       "  [101,\n",
       "   7564,\n",
       "   6163,\n",
       "   8403,\n",
       "   3221,\n",
       "   711,\n",
       "   749,\n",
       "   5688,\n",
       "   4689,\n",
       "   2768,\n",
       "   3315,\n",
       "   1416,\n",
       "   8024,\n",
       "   2940,\n",
       "   5143,\n",
       "   5320,\n",
       "   4924,\n",
       "   7937,\n",
       "   4172,\n",
       "   749,\n",
       "   4157,\n",
       "   511,\n",
       "   7241,\n",
       "   4669,\n",
       "   4802,\n",
       "   2141,\n",
       "   3300,\n",
       "   4157,\n",
       "   1510,\n",
       "   2418,\n",
       "   679,\n",
       "   6639,\n",
       "   4638,\n",
       "   7309,\n",
       "   7579,\n",
       "   8024,\n",
       "   2902,\n",
       "   7241,\n",
       "   6206,\n",
       "   4924,\n",
       "   4500,\n",
       "   1213,\n",
       "   8020,\n",
       "   679,\n",
       "   6814,\n",
       "   1377,\n",
       "   5543,\n",
       "   3221,\n",
       "   1728,\n",
       "   711,\n",
       "   3173,\n",
       "   3315,\n",
       "   2094,\n",
       "   679,\n",
       "   5650,\n",
       "   2533,\n",
       "   4500,\n",
       "   1213,\n",
       "   2902,\n",
       "   4638,\n",
       "   1333,\n",
       "   1728,\n",
       "   8021,\n",
       "   511,\n",
       "   1377,\n",
       "   5543,\n",
       "   3221,\n",
       "   3227,\n",
       "   1305,\n",
       "   1922,\n",
       "   4162,\n",
       "   1416,\n",
       "   8024,\n",
       "   2802,\n",
       "   3952,\n",
       "   2767,\n",
       "   3126,\n",
       "   3362,\n",
       "   679,\n",
       "   4415,\n",
       "   2682,\n",
       "   511,\n",
       "   102],\n",
       "  [101,\n",
       "   7946,\n",
       "   2421,\n",
       "   1557,\n",
       "   8013,\n",
       "   8013,\n",
       "   8013,\n",
       "   8110,\n",
       "   4157,\n",
       "   1288,\n",
       "   6842,\n",
       "   2791,\n",
       "   2218,\n",
       "   6206,\n",
       "   1217,\n",
       "   3119,\n",
       "   1288,\n",
       "   1921,\n",
       "   2791,\n",
       "   6589,\n",
       "   6820,\n",
       "   2523,\n",
       "   3566,\n",
       "   2791,\n",
       "   7313,\n",
       "   2523,\n",
       "   3266,\n",
       "   8013,\n",
       "   8013,\n",
       "   8013,\n",
       "   8013,\n",
       "   3683,\n",
       "   6772,\n",
       "   3191,\n",
       "   8013,\n",
       "   8013,\n",
       "   102],\n",
       "  [101,\n",
       "   2140,\n",
       "   2140,\n",
       "   671,\n",
       "   2259,\n",
       "   673,\n",
       "   702,\n",
       "   3299,\n",
       "   117,\n",
       "   679,\n",
       "   3221,\n",
       "   1922,\n",
       "   1599,\n",
       "   3614,\n",
       "   117,\n",
       "   738,\n",
       "   6387,\n",
       "   3221,\n",
       "   1728,\n",
       "   711,\n",
       "   5682,\n",
       "   2506,\n",
       "   679,\n",
       "   1916,\n",
       "   7831,\n",
       "   5683,\n",
       "   119,\n",
       "   5445,\n",
       "   684,\n",
       "   2190,\n",
       "   800,\n",
       "   5445,\n",
       "   6241,\n",
       "   117,\n",
       "   1377,\n",
       "   5543,\n",
       "   1922,\n",
       "   5042,\n",
       "   1296,\n",
       "   749,\n",
       "   119,\n",
       "   102],\n",
       "  [101,\n",
       "   7478,\n",
       "   2382,\n",
       "   671,\n",
       "   5663,\n",
       "   4638,\n",
       "   671,\n",
       "   3315,\n",
       "   741,\n",
       "   8024,\n",
       "   1041,\n",
       "   4007,\n",
       "   749,\n",
       "   969,\n",
       "   2682,\n",
       "   4638,\n",
       "   4415,\n",
       "   2682,\n",
       "   712,\n",
       "   721,\n",
       "   5682,\n",
       "   2506,\n",
       "   8024,\n",
       "   2456,\n",
       "   6379,\n",
       "   1157,\n",
       "   3684,\n",
       "   689,\n",
       "   4638,\n",
       "   5466,\n",
       "   1767,\n",
       "   3173,\n",
       "   782,\n",
       "   1283,\n",
       "   674,\n",
       "   679,\n",
       "   6206,\n",
       "   4692,\n",
       "   511,\n",
       "   102]],\n",
       " 'token_type_ids': [[0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]],\n",
       " 'attention_mask': [[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5313e04-9d87-4224-a18e-481520a4a43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "83\n",
      "37\n",
      "42\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "for i in data['input_ids']:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5a7a869-78d7-48ec-8a47-535ab43cbc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the data_collator\n",
    "data = data_collator(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97333dae-2d57-45d9-bf3f-aeb1bd8fcc68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,   122,  8021,  2242,  2391,  3221,   100,  7262,  7481,   100,\n",
       "          4638,  8024,   680,  2145,  3302,   722,  1184,  4638,  1726,  5031,\n",
       "          4685,  1353,  1557,  8020,  2769,   702,   782,  1599,  3614,  4836,\n",
       "          3763,  7481,  4638,  8024,  7262,  7481,  1922,  3230,  4706,  8021,\n",
       "          8013,   123,  8021,  7599,  2794,  1898,  7509,  3683,  2682,  6496,\n",
       "          4638,  1920,   679,  2208,  8013,   124,  8021,  8403,  2940,  9769,\n",
       "         11379,  8024,  5905,  2242,  8024,  7444,  6206,   934,  3121,  9324,\n",
       "          6392,  5390,  8020,  4801,  4669,  1346,  3144,  3121,   711, 11319,\n",
       "          3175,  2466,  8021,   102],\n",
       "        [  101,  7564,  6163,  8403,  3221,   711,   749,  5688,  4689,  2768,\n",
       "          3315,  1416,  8024,  2940,  5143,  5320,  4924,  7937,  4172,   749,\n",
       "          4157,   511,  7241,  4669,  4802,  2141,  3300,  4157,  1510,  2418,\n",
       "           679,  6639,  4638,  7309,  7579,  8024,  2902,  7241,  6206,  4924,\n",
       "          4500,  1213,  8020,   679,  6814,  1377,  5543,  3221,  1728,   711,\n",
       "          3173,  3315,  2094,   679,  5650,  2533,  4500,  1213,  2902,  4638,\n",
       "          1333,  1728,  8021,   511,  1377,  5543,  3221,  3227,  1305,  1922,\n",
       "          4162,  1416,  8024,  2802,  3952,  2767,  3126,  3362,   679,  4415,\n",
       "          2682,   511,   102,     0],\n",
       "        [  101,  7946,  2421,  1557,  8013,  8013,  8013,  8110,  4157,  1288,\n",
       "          6842,  2791,  2218,  6206,  1217,  3119,  1288,  1921,  2791,  6589,\n",
       "          6820,  2523,  3566,  2791,  7313,  2523,  3266,  8013,  8013,  8013,\n",
       "          8013,  3683,  6772,  3191,  8013,  8013,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0],\n",
       "        [  101,  2140,  2140,   671,  2259,   673,   702,  3299,   117,   679,\n",
       "          3221,  1922,  1599,  3614,   117,   738,  6387,  3221,  1728,   711,\n",
       "          5682,  2506,   679,  1916,  7831,  5683,   119,  5445,   684,  2190,\n",
       "           800,  5445,  6241,   117,  1377,  5543,  1922,  5042,  1296,   749,\n",
       "           119,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0],\n",
       "        [  101,  7478,  2382,   671,  5663,  4638,   671,  3315,   741,  8024,\n",
       "          1041,  4007,   749,   969,  2682,  4638,  4415,  2682,   712,   721,\n",
       "          5682,  2506,  8024,  2456,  6379,  1157,  3684,   689,  4638,  5466,\n",
       "          1767,  3173,   782,  1283,   674,   679,  6206,  4692,   511,   102,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c39c0a2-5f2f-4bb3-aeba-3dbcf5df759a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([5, 84])\n",
      "token_type_ids torch.Size([5, 84])\n",
      "attention_mask torch.Size([5, 84])\n",
      "labels torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "for k, v in data.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b73c6b7a-55df-45be-b0fb-dcef94476490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] È¢Ñ Ë£Ö linux ÊòØ ‰∏∫ ‰∫Ü ËäÇ ÁúÅ Êàê Êú¨ Âêß Ôºå Êç¢ Á≥ª Áªü Á®ç È∫ª ÁÉ¶ ‰∫Ü ÁÇπ „ÄÇ ÈîÆ Áõò Á°Æ ÂÆû Êúâ ÁÇπ Âìç Â∫î ‰∏ç Ë∂≥ ÁöÑ ÈóÆ È¢ò Ôºå Êåâ ÈîÆ Ë¶Å Á®ç Áî® Âäõ Ôºà ‰∏ç Ëøá ÂèØ ËÉΩ ÊòØ Âõ† ‰∏∫ Êñ∞ Êú¨ Â≠ê ‰∏ç Ëàç Âæó Áî® Âäõ Êåâ ÁöÑ Âéü Âõ† Ôºâ „ÄÇ ÂèØ ËÉΩ ÊòØ Êòæ Âç° Â§™ ÁÉÇ Âêß Ôºå Êâì Ê∏∏ Êàè Êïà Êûú ‰∏ç ÁêÜ ÊÉ≥ „ÄÇ [SEP] [PAD]'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(data['input_ids'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1fd8d9d9-5431-4d20-8b39-696ee7bab516",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45c1b649-d2f6-4ffc-94cd-39b50b62a971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 44:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6947501301765442,\n",
       " 'eval_accuracy': 0.5102040816326531,\n",
       " 'eval_runtime': 1.187,\n",
       " 'eval_samples_per_second': 82.56,\n",
       " 'eval_steps_per_second': 10.952}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Do a trail\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f99ba9e-afd1-4173-8f28-1619eec68a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adamw_torch\n"
     ]
    }
   ],
   "source": [
    "print(TrainingArguments.optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "40360fca-0a73-48be-90b6-73362944916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "227eb5c6-073d-4d93-822c-4b0cae155e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [494/494 02:17, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=494, training_loss=0.7254352029035931, metrics={'train_runtime': 137.4792, 'train_samples_per_second': 28.746, 'train_steps_per_second': 3.593, 'total_flos': 115669785493536.0, 'train_loss': 0.7254352029035931, 'epoch': 2.0})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3fa1ef2f-855c-402b-8e4d-7e73adaa5eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6929463148117065,\n",
       " 'eval_accuracy': 0.5102040816326531,\n",
       " 'eval_runtime': 0.4867,\n",
       " 'eval_samples_per_second': 201.337,\n",
       " 'eval_steps_per_second': 26.708,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0109b07b-72ad-43fb-a0fc-76e6d8361e75",
   "metadata": {},
   "source": [
    "## Save and load the model\n",
    "By default, all the model related files are saved in the checkpoint folders under output_dir. But you can also save it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "304643d1-e26c-4eb3-b913-afc201dc68a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir = './output_dir/save_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a5c080e-e544-445f-ac08-198b1f1f067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load a model, the old way of using pytorch doesn't work any more\n",
    "# model.load_state_dict(torch.load('./output_dir/save_model/pytorch_model.bin', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c207dcb-19ca-46ee-88ba-868701c0913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model with transformers API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "33dea81f-e7c6-43dd-94db-6bef0d807c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-2): 3 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoModelForSequenceClassification.from_pretrained('./output_dir/save_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af203149-076f-4f8d-9787-7b2ef994389a",
   "metadata": {},
   "source": [
    "### Resume from a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1e83a126-204b-445c-8d43-d214e7bcfccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [494/494 00:10, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=494, training_loss=0.061844929992428674, metrics={'train_runtime': 11.0817, 'train_samples_per_second': 356.624, 'train_steps_per_second': 44.578, 'total_flos': 115669785493536.0, 'train_loss': 0.061844929992428674, 'epoch': 2.0})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Patch Trainer to skip RNG state loading\n",
    "trainer._load_rng_state = lambda *args, **kwargs: None\n",
    "\n",
    "# Resume training\n",
    "trainer.train(resume_from_checkpoint='./output_dir/checkpoint-450')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d08595df-cd10-422f-8e1d-0e2e4930aa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.692955493927002,\n",
       " 'eval_accuracy': 0.5102040816326531,\n",
       " 'eval_runtime': 0.5656,\n",
       " 'eval_samples_per_second': 173.271,\n",
       " 'eval_steps_per_second': 22.985,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e8334efe-a335-4c61-b081-fc389ad487c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [494/494 00:17, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=494, training_loss=0.10614210584385675, metrics={'train_runtime': 17.3678, 'train_samples_per_second': 227.547, 'train_steps_per_second': 28.443, 'total_flos': 115669785493536.0, 'train_loss': 0.10614210584385675, 'epoch': 2.0})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint='./output_dir/checkpoint-420')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e4572c36-22f6-4e5e-a112-bcb363e2c2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6930639147758484,\n",
       " 'eval_accuracy': 0.5102040816326531,\n",
       " 'eval_runtime': 0.5189,\n",
       " 'eval_samples_per_second': 188.878,\n",
       " 'eval_steps_per_second': 25.055,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f4e2b2-afde-4fa9-807f-8def981fa08c",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "90186bb4-4edc-4249-9a83-16e3258dd081",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "for i, data in enumerate(trainer.get_eval_dataloader()):\n",
    "    break\n",
    "\n",
    "for k, v in data.items():\n",
    "    #put the data to gpu\n",
    "    data[k] = v.to('mps')\n",
    "\n",
    "out = model(**data)\n",
    "pred = out['logits'].argmax(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eafa0f85-8faa-42ca-9e4c-05b13fd4f5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 6006, 4197,  ...,    0,    0,    0],\n",
       "        [ 101, 7478, 2382,  ...,    0,    0,    0],\n",
       "        [ 101,  517, 4895,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 2791, 7313,  ...,    0,    0,    0],\n",
       "        [ 101,  976, 2339,  ..., 2742, 8013,  102],\n",
       "        [ 101, 6821,  702,  ...,    0,    0,    0]], device='mps:0'), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]], device='mps:0'), 'labels': tensor([0, 0, 1, 1, 1, 1, 1, 1], device='mps:0')}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "439ee09f-9355-475c-8492-bcc714be2722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('input_ids', tensor([[ 101, 6006, 4197,  ...,    0,    0,    0],\n",
       "        [ 101, 7478, 2382,  ...,    0,    0,    0],\n",
       "        [ 101,  517, 4895,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 2791, 7313,  ...,    0,    0,    0],\n",
       "        [ 101,  976, 2339,  ..., 2742, 8013,  102],\n",
       "        [ 101, 6821,  702,  ...,    0,    0,    0]], device='mps:0')), ('token_type_ids', tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0')), ('attention_mask', tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]], device='mps:0')), ('labels', tensor([0, 0, 1, 1, 1, 1, 1, 1], device='mps:0'))])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b064fc59-eef7-4c59-b682-6143c93402b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.6757, device='mps:0', grad_fn=<NllLossBackward0>), logits=tensor([[0.3124, 0.3848],\n",
       "        [0.3124, 0.3848],\n",
       "        [0.3124, 0.3848],\n",
       "        [0.3124, 0.3848],\n",
       "        [0.3124, 0.3848],\n",
       "        [0.3124, 0.3848],\n",
       "        [0.3124, 0.3848],\n",
       "        [0.3124, 0.3848]], device='mps:0', grad_fn=<LinearBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "41f1eb70-5d0c-41d6-afa4-02d97a7ef7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='mps:0')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fa969a12-77c4-4a62-8e26-d43c7a32170f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ËôΩ ÁÑ∂ cpu Âèë ÁÉ≠ Èáè ‰∏ç Â§ß Ôºå ‰ΩÜ Êú∫ Âô® Á°¨ Áõò Âèë ÁÉ≠ Èáè ËæÉ Â§ß Ôºå ÂØº Ëá¥ cpu È£é Êâá ‰∏ç ÂÅú Âú∞ È´ò ÈÄü ËΩ¨ Âä® Ôºå Êôö ‰∏ä ‰Ωø Áî® Ëßâ Âæó Âô™ Â£∞ Â§™ Â§ß Ôºå ÊØî Êàë ÁöÑ 15 ÂØ∏ ÁöÑ hp ÁöÑ Â£∞ Èü≥ Âìç Âæó Â§ö Ôºà Âêå Ê†∑ ÁöÑ Â∑• ‰Ωú Èáè Ôºå ‰∏ç Ë∞à ÈÄü Â∫¶ ‰∫Ü Ôºâ Ôºå Ëøô ÊòØ ‰∏™ ÈÅó ÊÜæ ÔºÅ\n",
      "label =  0\n",
      "predictions =  1\n",
      "Èùû Â∏∏ ‰∏Ä Ëà¨ ÁöÑ ‰∏Ä Êú¨ ‰π¶ Ôºå ÂÖÖ Êª° ‰∫Ü ÂÅá ÊÉ≥ ÁöÑ ÁêÜ ÊÉ≥ ‰∏ª ‰πâ Ëâ≤ ÂΩ© Ôºå Âª∫ ËÆÆ Âàö ÊØï ‰∏ö ÁöÑ ËÅå Âú∫ Êñ∞ ‰∫∫ ÂçÉ ‰∏á ‰∏ç Ë¶Å Áúã „ÄÇ\n",
      "label =  0\n",
      "predictions =  1\n",
      "„Ää Á¶ª Â©ö „Äã ‰πü ËØª ÂÆå ‰∫Ü „ÄÇ Á¶ª Â©ö Áøª ËØë Êàê Êõ¥ Êòé ÁôΩ ÁöÑ ËØù Ôºå Â∫î ËØ• Âè´ Âπª ÁÅ≠ „ÄÇ ÊâÄ Êúâ ÁöÑ ÂØπ Áîü Ê¥ª ÁöÑ Â∏å Êúõ ÈÉΩ ‰º¥ Èöè ÁùÄ ËØ• Á¶ª Â©ö ÁöÑ ‰∫∫ ÁöÑ ‰∏ç Á¶ª Â©ö ËÄå Á†¥ ÁÅ≠ ‰∫Ü „ÄÇ\n",
      "label =  1\n",
      "predictions =  1\n",
      "„Ää Èò¥ Èò≥ Â∏à. Êô¥ Êòé Âèñ Áò§ „Äã Ëøô Êú¨ ‰π¶ ‰π∞ Âõû Êù• Êîæ Âú® ‰π¶ Êû∂ ‰∏ä Â•Ω ÊÆµ Êó• Â≠ê Ôºå Êàë ÈÉΩ ÂÆå ‰∫Ü ÊòØ ‰ªÄ ‰πà Êó∂ ÂÄô ‰π∞ ÁöÑ ‰∫Ü „ÄÇ Âú® Êï¥ ÁêÜ ‰∏ú Ë•ø ÁöÑ Êó∂ ÂÄô Áúã Âà∞ Ê≠£ Â•Ω Áù° ‰∏ç ÁùÄ Â∞± Áúã Áúã Âêß „ÄÇ Áúã ÂÆå ‰πã Âêé Ëßâ Âæó Êúâ ÁÇπ Êêû Á¨ë „ÄÇ ÊòØ Âè§ ‰ª£ Âæó È¨º ÊØî ËæÉ Ë†¢ Âë¢ Ôºå Â•Ω ÊòØ Êó• Êú¨ ÈÇ£ Ëæπ Âæó È¨º ÊØî ËæÉ Ë†¢ Ôºü Âõ† ‰∏∫ Áúã Áé∞ ‰ª£ Âæó È¨º ÊïÖ ‰∫ã ÈÉΩ ËØ¥ Âà∞ ÈÇ£ ‰∫õ È¨º ‰∫ã Âæà Á≤æ Êòé Ôºå ËÄå ‰∏î Áã° Áåæ „ÄÇ Êàë ÊÉ≥ ÈóÆ ÁöÑ Â∞± ‰∫ã Êô¥ Êòé ‰∏ç ÊòØ Êúâ Âºè Á•û Âêó Ôºü ‰∏∫ ‰ªÄ ‰πà Âà∞ Êúâ ‰∫ã ÁöÑ Êó∂ ÂÄô Âºè Á•û ‰∏ç Â∏Æ Âøô? Ëøá ÊÄª Áªì ÈÉΩ ‰∏ç Èîô Ôºå ËÆ© Êàë Êúâ ÊÉ≥ ‰π∞ ÂÖ∂ ‰ªñ Âá† ÈÉ® Âõû Êù• Áúã ‰∏™ ÂÆå Êï¥ „ÄÇ\n",
      "label =  1\n",
      "predictions =  1\n",
      "Â∏Æ Êúã Âèã ‰π∞ ÁöÑ Âè∞ Âºè „ÄÅ Á¨î ËÆ∞ Êú¨ Ê∏Ö ‰∏Ä Ëâ≤ ÁöÑ hp Ôºå ÈÖç ÁΩÆ Êå∫ ‰∏ç Èîô ÁöÑ Ôºå ÊÄß ‰ª∑ ÊØî Á™Å Âá∫ „ÄÇ hp Â§ß ÂìÅ Áâå Ôºå 4000 Â§ö ÂÖÉ ÁöÑ È¶ñ ÈÄâ ÔºÅ\n",
      "label =  1\n",
      "predictions =  1\n",
      "Êàø Èó¥ Êñ∞ Ë£Ö ‰øÆ ÁöÑ, ‰Ωú ‰∏∫ ‰∏á Ë±™ ÁöÑ Èáë Âç° ‰ºö Âëò, Áªô Êàë Âçá Á∫ß ÂÖç Ë¥π ÂÆΩ Â∏¶ Âíå ÂÖç Ë¥π Êó© È§ê, Ëøô ÁÇπ ÊØî Êó† Èî° ‰∏á ÊÄ° Â•Ω Âæà Â§ö ‰∫Ü. Ââç Âè∞ ÁöÑ Á¨ë ËÑ∏ ‰∏ç Â§ö, ‰ΩÜ Âíå ‰πã Ââç Áõ∏ ÊØî ÁöÑ ËØù, Ëøõ Ê≠• Âæà Â§ö ‰∫Ü. Èºì Âä± ‰∏Ä ‰∏ã.\n",
      "label =  1\n",
      "predictions =  1\n",
      "ÂÅö Â∑• ‰∏ç Èîô Ôºå ‰∏ª Ë¶Å ‰∫ã ‰ª∑ Èí± ÂÆû Âú® Ôºå 2400xt Ôºå Áúã ‰∫Ü ÁΩë ‰∏ä ÁöÑ Á¨î ËÆ∞ Êú¨ Êòæ Âç° Êéí Ë°å Ôºå Ëøò ÊòØ ÊØî ËæÉ Èù† Ââç ÁöÑ Ôºå Ë∑ü 9300 Êúâ ÁöÑ ÊØî Ôºå ‰∫é ÊòØ Â∞± ÈÄâ ‰∫Ü ÂÆÉ „ÄÇ ‰π∞ ‰πã Ââç Áúã ‰∫Ü 3 Êòü ÁöÑ Ôºå 3400 Â∏¶ 9200gs Áã¨ Êòæ ÁöÑ ÈÇ£ Ê¨æ Ôºå Ë¶Å 3999 Ôºå Âè™ Â§ö ‰∫Ü ‰∏™ ÊëÑ ÂÉè Â§¥ Ôºå Êàë ‰π∞ ‰πã Ââç Ê≤° Áúã Ê∏Ö Ê•ö Ôºå ‰ª• ‰∏∫ Ê≠§ Ê¨æ ‰πü ÊòØ Êúâ ÊëÑ ÂÉè Â§¥ ÁöÑ Ôºå Ê±ó ÔºÅ ÔºÅ Âõû Âéª ÂºÄ ‰∫Ü cs Ôºå ÂºÄ Êª° 32 ‰∏™ Áîµ ËÑë ‰∏ç Âç° Ôºå Êòæ Âç° Ëøò ‰∏ç Èîô Ôºå Ëøò Êúâ ‰∏ä Èù¢ ÁöÑ ÈÇ£ ‰∏™ Â£∞ Èü≥ ÁöÑ Ëß¶ Êë∏ Âæà ÁÅµ Êïè Ôºå Êë∏ ‰∏Ä ‰∏ã Â∞± Êúâ Âèç Êò† ‰∫Ü „ÄÇ Âæà ÁàΩ ÔºÅ Â§ñ ËßÇ ÊòØ Ëìù Ëâ≤ ÁöÑ Ôºå ÂÖ∂ ÂÆû Êú¨ ‰∫∫ Êõ¥ Âñú Ê¨¢ Èªë ÁöÑ Ôºå Âè™ ÊòØ Ê≤° Êúâ „ÄÇ ÈÅó ÊÜæ ÔºÅ\n",
      "label =  1\n",
      "predictions =  1\n",
      "Ëøô ‰∏™ ÂÆæ È¶Ü ÊØî ËæÉ Èôà Êóß ‰∫Ü Ôºå Áâπ ‰ª∑ ÁöÑ Êàø Èó¥ ‰πü Âæà ‰∏Ä Ëà¨ „ÄÇ ÊÄª ‰Ωì Êù• ËØ¥ ‰∏Ä Ëà¨\n",
      "label =  1\n",
      "predictions =  1\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print(tokenizer.decode(data['input_ids'][i], skip_special_tokens = True))\n",
    "    print('label = ' , data['labels'][i].item())\n",
    "    print('predictions = ', pred[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add2e92-253f-44d7-9be5-62b949ceb991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
