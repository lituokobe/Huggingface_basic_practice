{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfab3b3a-4a4d-4b81-9314-6c1400d9f69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f704e2d-b88b-4e57-8787-98a36bfb87f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a54de8f2-23af-4144-ab3d-50679d91dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use GPU on mac\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae7907e-fb4e-4508-a536-b1e1658c95ba",
   "metadata": {},
   "source": [
    "## Use GPU to train\n",
    "- Put the model onto GPU\n",
    "- Put the training data of each batch onto GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da83016d-e229-41ee-854e-494988fe80fe",
   "metadata": {},
   "source": [
    "In this project, we will use some stored data from torchvision.  \n",
    "torchvision has some default datasets.\n",
    "\n",
    "`transform.ToTensor`: convert data to tensor, values are between 0 and 1, put channel to the first dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc1d1e8c-c4d2-4e60-be6b-24026a399f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "#transform is dedicated for data enforcement and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "078aadac-a078-4a24-9427-61ace4637f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = transforms.Compose([transforms.ToTensor()])\n",
    "tran_ds = datasets.MNIST('./data', train = True, transform=transformation, download=True) # the directory is where you download the data to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "536d1990-283e-4a63-8699-b2f4140ed312",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = datasets.MNIST('./data', train = False, transform=transformation, download=True) # the directory is where you download the data to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd3e936-ba8f-4d48-9182-9ac9d8fed932",
   "metadata": {},
   "source": [
    "The data is downaloaded to folder './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7978a4-895e-495b-9738-3254f3d352a0",
   "metadata": {},
   "source": [
    "### Convert the datat to DataLoad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3cad8f36-6bb0-4cdb-b193-0f0b81b91fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(tran_ds, batch_size = 64, shuffle = True)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "416f4994-47a2-4518-95d2-81e7d15b89d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dl))[0].shape\n",
    "#64 in batch, 1 channel, 28*28 picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fa1323a0-6813-44ba-a8ec-ae1ad44647f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dl))[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12406232-fbea-4b72-bbab-47aafc53db50",
   "metadata": {},
   "source": [
    "Illustrate some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6ec8e53-334e-4844-9eb9-fdd4782de3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.squeeze(next(iter(train_dl))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6fb89f6d-38e0-4104-8539-3e90ac03aaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x137ed9120>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd6764-d3c8-446a-893a-c3d87948cc9a",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "93a2f2cd-2445-491d-8a55-b41e6c263db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3) #out 64, 32, 26, 26\n",
    "        self.pool1 = nn.MaxPool2d(2) #out 64, 32, 13, 13\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3) #out 64, 64, 11, 11\n",
    "        #another layer of pooling: out 64, 64, 5, 5\n",
    "        \n",
    "        self.linear1 = nn.Linear(64*5*5, 256)\n",
    "        self.linear2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = F.relu(self.conv1(input))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        #flatten\n",
    "        x = x.view(-1, 64*5*5)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c3d58e89-37c0-4e05-9254-4d2cdf68e2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model1(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (linear1): Linear(in_features=1600, out_features=256, bias=True)\n",
       "  (linear2): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model1()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6f3e7e1c-777c-4770-a641-04988f4409d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8cf33832-9046-41df-8a28-3ffc52bfd0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1bffff12-f3cb-4e96-a4c8-88e05b92d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit (epoch, model, train_loader, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        #put the data to GPU\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred = torch.argmax(y_pred, dim = 1)\n",
    "            correct += (y_pred==y).sum().item()\n",
    "            total += y.size(0)\n",
    "            running_loss +=loss.item()\n",
    "            \n",
    "    epoch_loss = running_loss/len(train_loader.dataset)\n",
    "    epoch_acc = correct/total\n",
    "    \n",
    "    #test\n",
    "    test_correct = 0\n",
    "    test_running_loss = 0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in train_loader:\n",
    "            #put the data to GPU\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            y_pred = torch.argmax(y_pred, dim = 1)\n",
    "            test_correct += (y_pred==y).sum().item()\n",
    "            test_total += y.size(0)\n",
    "            test_running_loss +=loss.item()\n",
    "    \n",
    "    test_epoch_loss = test_running_loss/len(test_loader.dataset)\n",
    "    test_epoch_acc = test_correct/test_total\n",
    "\n",
    "    print(f'Epoch: {epoch}, loss:{round(epoch_loss, 3)}, accuracy: {round(epoch_acc, 3)}, test_loss: {round(test_epoch_loss, 3)}, test_accuracy: {round(test_epoch_acc, 3)}')\n",
    "    \n",
    "    return  epoch_loss, epoch_acc, test_epoch_loss, test_epoch_acc  \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c3eb202a-b8b5-4b73-aa22-fb6ef2cfaf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss:0.003, accuracy: 0.948, test_loss: 0.005, test_accuracy: 0.983\n",
      "Epoch: 1, loss:0.001, accuracy: 0.983, test_loss: 0.004, test_accuracy: 0.988\n",
      "Epoch: 2, loss:0.001, accuracy: 0.988, test_loss: 0.002, test_accuracy: 0.992\n",
      "Epoch: 3, loss:0.0, accuracy: 0.991, test_loss: 0.002, test_accuracy: 0.994\n",
      "Epoch: 4, loss:0.0, accuracy: 0.994, test_loss: 0.001, test_accuracy: 0.997\n",
      "Epoch: 5, loss:0.0, accuracy: 0.995, test_loss: 0.001, test_accuracy: 0.996\n",
      "Epoch: 6, loss:0.0, accuracy: 0.996, test_loss: 0.001, test_accuracy: 0.997\n",
      "Epoch: 7, loss:0.0, accuracy: 0.997, test_loss: 0.001, test_accuracy: 0.996\n",
      "Epoch: 8, loss:0.0, accuracy: 0.997, test_loss: 0.001, test_accuracy: 0.998\n",
      "Epoch: 9, loss:0.0, accuracy: 0.997, test_loss: 0.001, test_accuracy: 0.998\n",
      "Epoch: 10, loss:0.0, accuracy: 0.998, test_loss: 0.0, test_accuracy: 0.999\n",
      "Epoch: 11, loss:0.0, accuracy: 0.998, test_loss: 0.001, test_accuracy: 0.997\n",
      "Epoch: 12, loss:0.0, accuracy: 0.998, test_loss: 0.0, test_accuracy: 0.998\n",
      "Epoch: 13, loss:0.0, accuracy: 0.998, test_loss: 0.0, test_accuracy: 0.999\n",
      "Epoch: 14, loss:0.0, accuracy: 0.999, test_loss: 0.0, test_accuracy: 0.999\n",
      "Epoch: 15, loss:0.0, accuracy: 0.999, test_loss: 0.0, test_accuracy: 0.999\n",
      "Epoch: 16, loss:0.0, accuracy: 0.999, test_loss: 0.0, test_accuracy: 0.999\n",
      "Epoch: 17, loss:0.0, accuracy: 0.999, test_loss: 0.001, test_accuracy: 0.998\n",
      "Epoch: 18, loss:0.0, accuracy: 0.999, test_loss: 0.0, test_accuracy: 1.0\n",
      "Epoch: 19, loss:0.0, accuracy: 0.999, test_loss: 0.0, test_accuracy: 0.999\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss, epoch_acc, test_epoch_loss, test_epoch_acc = fit(epoch, model, train_dl, test_dl)\n",
    "    train_loss.append(epoch_loss)\n",
    "    train_acc.append(epoch_acc)\n",
    "    test_loss.append(test_epoch_loss)\n",
    "    test_acc.append(test_epoch_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba75418c-23fa-449f-b598-7db002c49c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d193cc54-26f9-4573-812a-9efcc8d5b2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad9ec65-ddde-4d44-98a4-a02a2279314c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
